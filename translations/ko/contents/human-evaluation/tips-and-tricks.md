# 팁과 요령
다음은 평가 데이터셋을 구축하기 위해 인간 평가자를 활용할 때 고려할 만한 몇 가지 실용적인 팁입니다. 아직 읽지 않았다면, 먼저 "인간 평가자 활용하기(Using human annotators)" 페이지를 읽고 이 페이지로 돌아오는 것을 권장합니다.

## 작업 설계하기

- **단순할수록 좋습니다**: 평가 작업은 불필요하게 복잡해질 수 있으므로 최대한 단순하게 유지하세요. 평가자의 인지 부담을 최소화하면 집중력을 유지하고 더 높은 품질의 평가를 수행하는 데 도움이 됩니다.

- **보여주는 내용을 확인하세요**: 평가자가 작업을 완료하는 데 필요한 정보만 보여주고, 추가적인 편향을 초래할 수 있는 정보는 포함하지 않도록 하세요.

- **평가자의 시간을 고려하세요**: 정보가 표시되는 위치와 방식에 따라 추가 작업이나 인지 부담이 생길 수 있으며, 이는 결과의 품질에 부정적인 영향을 미칠 수 있습니다. 예를 들어, 텍스트와 작업이 함께 보이도록 하고 불필요한 스크롤을 피하세요. 여러 작업을 결합하고 한 작업의 결과가 다른 작업에 영향을 미치는 경우 순차적으로 표시할 수 있습니다. 평가 도구에서 모든 요소가 어떻게 표시되는지 생각해보고 더 단순화할 수 있는 방법이 있는지 확인하세요.

- **설정을 테스트하세요**: 작업을 설계하고 가이드라인을 마련한 후에는 전체 팀을 참여시키기 전에 몇 가지 샘플로 직접 테스트하고 필요에 따라 반복적으로 개선하세요.

## 평가 진행 중

- **평가자는 독립적으로 작업해야 합니다**: 평가자들이 작업 중에 서로 도움을 주거나 서로의 작업을 보지 않는 것이 좋습니다. 자신의 편향을 전파하고 평가 편차를 일으킬 수 있기 때문입니다. 일관성은 항상 포괄적인 가이드라인을 통해 이루어져야 합니다. 새로운 팀원은 먼저 별도의 데이터셋으로 훈련시키거나, 평가자 간 일치도 지표를 사용하여 팀이 일관성을 유지하는지 확인할 수 있습니다.

- **일관성이 중요합니다**: 가이드라인에 중요한 변경사항을 적용한 경우(예: 정의나 지침 변경, 라벨 추가/제거), 평가된 데이터를 다시 검토할 필요가 있는지 고려하세요. 최소한 `guidelines-v1`과 같은 메타데이터 값을 통해 데이터셋의 변경사항을 추적해야 합니다.

## 인간-기계 혼합 평가

때로는 팀이 시간과 자원에 제약을 받지만 인간 평가의 장점을 포기하고 싶지 않을 수 있습니다. 이런 경우, 모델의 도움을 받아 작업을 더 효율적으로 만들 수 있습니다.

- **모델 지원 평가**: 모델의 예측이나 생성 결과를 사전 평가로 활용하여 평가 팀이 처음부터 시작할 필요가 없게 할 수 있습니다. 단, 이 방법은 모델의 편향이 인간 평가에 영향을 미칠 수 있고, 모델의 정확도가 낮으면 평가자의 작업량이 증가할 수 있습니다.

- **모델 평가자 감독**: "모델을 평가자로 활용(Model as a judge)" 방법론의 강점과 결과를 검증하거나 폐기하는 인간 감독자를 결합할 수 있습니다. "인간 평가의 장단점" 섹션에서 논의된 편향이 여기에도 적용된다는 점을 유의하세요.

- **경계 사례 식별**: 더 빠른 작업을 위해 여러 모델의 의견을 활용하고, 모델 간 의견이 일치하지 않거나 동점이 발생한 경우에만 인간 감독자가 개입하도록 할 수 있습니다. 다시 말하지만, "인간 평가의 장단점"에서 논의된 편향에 주의하세요.

## 엔드 투 엔드 튜토리얼

이러한 팁을 따라 자신만의 맞춤형 평가 설정을 구축하려면 Argilla에서 제공하는 [실용적인 튜토리얼](https://github.com/argilla-io/argilla-cookbook/tree/main/domain-eval)을 따를 수 있습니다. 이 튜토리얼은 [Argilla](https://github.com/argilla-io/argilla/)와 [distilabel](https://github.com/argilla-io/distilabel)을 사용하여 합성 데이터와 수동 평가를 통해 도메인에 맞는 맞춤형 평가 작업을 구축하는 과정을 안내합니다. 이 가이드는 도메인 문서에서 시작하여 [lighteval](https://github.com/huggingface/lighteval)로 모델을 평가하는 데 사용할 수 있는 맞춤형 평가 작업으로 이어집니다.