# 모델 추론 및 평가

## 소개
현재 대규모 언어 모델은 간단한 방식으로 작동합니다: 텍스트 입력이 주어지면, 그에 대한 타당한 다음 내용을 예측하는 방법을 학습합니다.

이는 두 단계로 이루어집니다.
### 토큰화
입력 텍스트(추론 시 *프롬프트*라고 함)는 먼저 *토큰*으로 분할됩니다. 토큰은 각각 숫자와 연관된 작은 텍스트 단위(한 글자 또는 여러 글자, 단어 수준까지)입니다. 모델이 파싱할 수 있는 토큰의 전체 범위를 *어휘(vocabulary)*라고 합니다. *(이에 대해 더 깊이 이해하려면 [토큰화](https://github.com/huggingface/evaluation-guidebook/blob/main/contents/general-knowledge/tokenization.md) 페이지를 참조하세요)*.

### 예측

![](https://github.com/huggingface/evaluation-guidebook/blob/main/assets/llm_tk_1.png?raw=true)

이 입력 텍스트로부터 LLM은 전체 어휘에 대해 가장 가능성 높은 다음 토큰의 확률 분포를 생성합니다. 계속해서 생성하기 위해, 가장 확률이 높은 토큰(더 흥미로운 출력을 얻기 위해 약간의 무작위성을 추가할 수 있음)을 다음 토큰으로 선택한 다음, 새 토큰을 프롬프트의 끝으로 사용하여 작업을 반복합니다.

## 무엇을 예측하고 싶은가?
LLM 평가는 주로 2가지 범주로 나뉩니다:
- 프롬프트와 하나(또는 여러 개)의 답변이 주어졌을 때, 내 모델에서 해당 답변의 확률은 얼마인가?
- 프롬프트가 주어졌을 때, 내 모델은 어떤 텍스트를 생성하는가?

### 로그 가능도 평가
로그 가능도 평가에서는 프롬프트가 주어졌을 때 하나 또는 여러 선택지의 조건부 확률을 원합니다 - 다시 말해, 특정 입력이 주어졌을 때 특정 연속 텍스트가 나올 가능성은 얼마인가?
따라서:
- 각 선택지를 프롬프트와 연결하여 LLM에 전달하면, 이전 토큰에 따라 각 토큰의 로짓(logit)을 출력합니다
- 마지막 로짓(선택 토큰과 연관된)만 유지하고, 로그 소프트맥스를 적용하여 로그 확률을 얻습니다(범위는 `[0-1]` 대신 `[-inf, 0]`)
- 그런 다음 모든 개별 토큰의 로그 확률을 합산하여 전체 선택의 로그 확률을 얻습니다
- 마지막으로 선택 길이에 따른 정규화를 적용할 수 있습니다

![](https://github.com/huggingface/evaluation-guidebook/blob/main/assets/llm_logprob.png?raw=true)

이를 통해 다음과 같은 메트릭을 적용할 수 있습니다:
- 위 그림과 같이 여러 선택지 중에서 모델이 선호하는 답변을 얻습니다. (*그러나 이는 자유롭게 생성했을 때 다른 것을 생성했을 모델의 점수에 유리할 수 있습니다. 그림에서 `Zygote`와 같은 경우입니다.*)
- 단일 선택지의 확률이 0.5 이상인지 테스트합니다
- 모델 보정(calibration)을 연구합니다. 잘 보정된 모델은 정확한 답변이 가장 높은 확률을 가지는 모델입니다.
  *(보정에 대해 더 알아보려면, Anthropic의 [이 논문](https://arxiv.org/abs/2207.05221)에서 보정이 무엇인지, 어떻게 감지하는지, 모델을 잘 보정되도록 훈련하는 방법을 확인할 수 있으며, [이 논문](https://arxiv.org/abs/2311.14648)에서는 보정의 가능한 한계에 대해 알아볼 수 있습니다.)*

### 생성 평가
생성 평가에서는 입력 프롬프트가 주어졌을 때 모델이 생성하는 텍스트를 원합니다.

이는 자기회귀(auto-regressive) 방식으로 얻어집니다: 프롬프트를 모델에 전달하고, 가장 가능성 높은 다음 토큰을 찾아 모델의 "첫 번째 선택 토큰"으로 선택한 다음, 생성 종료 조건(최대 길이, 생성을 중지하는 특수 토큰 등)에 도달할 때까지 반복합니다. 모델이 생성한 모든 토큰은 프롬프트에 대한 답변으로 간주됩니다.

![](https://github.com/huggingface/evaluation-guidebook/blob/main/assets/llm_gen.png?raw=true)

그런 다음 이 생성을 참조와 비교하고 둘 사이의 거리를 점수화할 수 있습니다(정확한 일치와 같은 단순한 메트릭, BLEU와 같은 더 복잡한 메트릭, 또는 판단 모델을 사용).

### 더 알아보기
- ⭐ [MMLU를 평가하는 여러 방법에 관한 블로그](https://huggingface.co/blog/open-llm-leaderboard-mmlu), Hugging Face 팀 작성. 다중 선택 로그 가능도 평가와 생성 평가 사이의 차이점에 대해 더 깊이 알아보고 싶다면 읽어보는 것을 추천합니다. 점수 변화와 관련하여 무엇을 의미할 수 있는지도 포함되어 있습니다.
  - 위의 일러스트레이션은 블로그에서 가져온 것으로 Thom Wolf가 만들었습니다.
- ⭐ [위 추론 방법에 대한 아름다운 수학적 형식화](https://arxiv.org/abs/2405.14782v2), EleutherAI에서 작성. 부록으로 바로 가보세요.

## 모델 출력 제한하기
많은 경우에 모델 출력이 특정 형식을 따르기를 원합니다. 예를 들어 참조와 비교하기 위해서입니다.

### 프롬프트 사용하기
가장 쉬운 방법은 모델이 어떻게 답변해야 하는지에 대한 매우 구체적인 지침이 포함된 작업 프롬프트를 추가하는 것입니다(`숫자 답변은 숫자로 제공하세요.`, `약어를 사용하지 마세요.` 등).

항상 작동하지는 않지만 고성능 모델에는 충분히 좋은 방법입니다. 이는 [GAIA](https://huggingface.co/papers/2311.12983) 논문에서 우리가 따른 접근 방식이며, 영감을 얻고 싶다면 [리더보드](https://huggingface.co/spaces/gaia-benchmark/leaderboard)의 제출 탭에서 우리의 작업 프롬프트를 찾을 수 있습니다.

### 퓨샷과 문맥 내 학습
다음 방법은 "문맥 내 학습(in context learning)"이라고 불리는 것을 통해 모델을 제한하는 것입니다. 프롬프트에 예시를 제공함으로써(`퓨샷 프롬프팅(few-shot prompting)`이라고 함), 모델은 실제 샘플에 대해 반복된 프롬프트 형태를 따르도록 암묵적으로 편향됩니다.

이는 2023년 말까지 전반적으로 잘 작동하던 방법입니다! 그러나 지시 튜닝 방법의 광범위한 채택과 모델 사전 훈련의 후반 단계에서 지시 데이터의 추가(지속적인 사전 훈련)는 최근 모델들이 특정 출력 형식으로 편향되게 만든 것으로 보입니다([여기](https://arxiv.org/abs/2407.07890)에서 `테스트 작업에 대한 훈련`이라고 불리며, 제가 `프롬프트 형식 과적합`이라고 부르는 것입니다). 또한 이 방법은 작은 컨텍스트 크기를 가진 오래된 모델에서는 제한적일 수 있습니다. 일부 퓨샷 예시가 컨텍스트 창에 맞지 않을 수 있기 때문입니다.

### 구조화된 텍스트 생성
구조화된 텍스트 생성은 출력이 문법이나 정규 표현식 등으로 정의된 특정 경로를 따르도록 제한합니다. `outlines` 라이브러리는 유한 상태 기계(finite state machines)를 사용하여 이를 구현하며, 이는 매우 깔끔합니다. (JSON 생성을 위한 인터리브드 생성과 같은 다른 접근 방식도 있지만, FSM 방식이 제가 가장 좋아하는 방식입니다).

구조화된 생성을 사용할 때 어떤 일이 일어나는지 더 이해하려면, 허깅페이스에서 작성한 [블로그](https://huggingface.co/blog/evaluation-structured-outputs)를 확인할 수 있습니다: 구조화된 생성은 평가에서 프롬프트 변동성을 줄이고, 결과와 순위를 더 안정적으로 만듭니다. 또한 구조화된 생성과 관련된 흥미로운 구현과 관찰을 위해 전체 `outlines` [블로그](https://blog.dottxt.co/)를 확인할 수 있습니다.

그러나 최근 일부 [연구](https://arxiv.org/abs/2408.02442)에 따르면 구조화된 생성이 사전 확률 분포를 예상 확률 분포에서 너무 멀리 이동시켜 일부 작업(추론 등)에서 모델 성능을 저하시킬 수 있다고 합니다.

### 더 알아보기
- ⭐ [구조화된 생성에서 유한 상태 기계의 작동 방식 이해하기](https://blog.dottxt.co/coalescence.html), Outlines 작성. 그들의 방법이 어떻게 작동하는지에 대한 매우 명확한 가이드입니다!
- [outlines 방법 논문](https://arxiv.org/abs/2307.09702), 위 내용에 대한 더 학술적인 설명
- [인터리브드 생성](https://github.com/guidance-ai/guidance?tab=readme-ov-file#guidance-acceleration), 특정 출력 형식에 대한 생성을 제한하는 또 다른 방법
