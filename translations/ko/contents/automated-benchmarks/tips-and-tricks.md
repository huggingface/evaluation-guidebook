# 팁과 요령

## 데이터 오염 관리

일반적으로 인터넷에 공개적으로 제공되는 데이터셋은 오염되었거나 오염될 것이라고 가정해야 합니다.

이를 완화하기 위한 해결책은 다음과 같습니다:

- 평가 세트에 **카나리 문자열**(예: [BigBench](https://github.com/google/BIG-bench)처럼)을 제공하는 것: 모델 제작자가 훈련 세트에서 찾을 수 있는 특정 문자 조합으로, 평가 데이터가 포함되어 있음을 나타냅니다
- 웹 크롤러가 쉽게 구문 분석할 수 없도록 평가 세트를 **[암호화](https://arxiv.org/abs/2309.16575)하거나 [제한된 접근](https://huggingface.co/datasets/Idavidrein/gpqa)**으로 제공하여 실수로 훈련 세트에 포함되지 않도록 합니다
- [동적 벤치마크](https://arxiv.org/abs/2104.14337) 실행: 모델이 "답을 외울 수 없도록" 정기적으로 업데이트되는 벤치마크(하지만 데이터셋 비용이 더 많이 듭니다)
- 벤치마크를 실행하는 경우, 사후에 [데이터 오염 감지](https://arxiv.org/abs/2311.06233)를 시도(예: 생성 복잡도를 살펴보거나 프롬프트의 적대적 버전을 설계하는 방법 - 그러나 어떤 방법도 완벽한 오염 감지 방법은 아닙니다)

그러나 데이터셋이 오염되었다고 해서 모델 훈련하는데 있어서 무의미 하다는 것은 아닙니다.

## 실제로 마주할 수 있는 문제들

### 미세 조정된 모델, 시스템 프롬프트 및 채팅 템플릿

많은 지시 조정된 모델들은 다음을 확인하지 않으면 성능이 매우 저하됩니다:

- 추론 시작 시 시스템 프롬프트 추가
- 채팅 템플릿을 사용한 프롬프팅(일반적으로 대화 차례에 `Assistant`와 `User` 접두사 추가 - [이 멋진 가이드](https://huggingface.co/docs/transformers/main/en/chat_templating)에서 자세히 알아보세요)

또한 다른 토크나이저가 특히 채팅 템플릿과 관련하여 동일하게 작동한다고 가정하지 않는 것이 매우 중요합니다. [이 트윗](https://x.com/danielhanchen/status/1796952220619157694)에서 가져온 토큰화 간격과 채팅 템플릿에 관한 이 멋진 그림에서 볼 수 있습니다.

![간격, 토큰화 및 템플릿](https://pbs.twimg.com/media/GPANfpiasAA9b6F?format=png&name=medium)

### 토큰화

1. **컨텍스트와 선택지를 함께 또는 별도로 토큰화하기**

MCQA 평가를 살펴볼 때, 일반적으로 컨텍스트와 선택지를 함께 토큰화하는 것이 좋습니다. 이는 모델에게 자연스러운 토큰 시퀀스를 만들어 줍니다.

그러나 일부 토크나이저(예: [Llama 토크나이저](https://github.com/EleutherAI/lm-evaluation-harness/pull/531#issuecomment-1595586257))는 `enc(context + choice) = enc(context) + enc(choice)`를 만족하지 않습니다(공백을 추가하거나 제거함). 이는 컨텍스트 토큰이 선택지로 "흘러들어가" 비교를 방해할 수 있기 때문에 선택지의 로그확률을 비교하기 어렵게 만듭니다.

따라서 이런 경우에는 컨텍스트와 선택지의 토큰을 별도로 계산한 다음, 추가되었을 수 있는 특수 문장 시작/끝 토큰을 제거한 후 연결하는 것이 좋을 수 있습니다.

2. **문장 시작 및 끝 토큰에 주의하기**

`Gemma`와 같은 일부 모델은 추론 시 [문장 시작 토큰 포함](https://github.com/EleutherAI/lm-evaluation-harness/pull/1465)에 매우 민감합니다. 이런 일이 발생하는지 확인하기 위해 몇 가지 실험을 수행하고, 평가할 때 이러한 토큰을 수동으로 추가해야 할 수도 있습니다.

또한 모델이 예상대로 문장 끝 토큰(예: `\n`)에서 멈추지 않는 문제가 발생할 수 있습니다. 이는 모델이 이 토큰만 예측하는 것이 아니라 상위 수준 토큰에 포함된 형태로 예측하기 때문입니다(예: `\n\n`은 특히 코드 모델에서 단일 토큰일 수 있음). 이 경우 생성된 텍스트를 "역추적"하여 메트릭을 계산하기 전에 적절한 지점에서 생성된 문장을 잘라내는지 확인하기 위한 특정 검사를 추가해야 할 수 있습니다.

3. **다국어 및 토큰화**

다국어 평가를 살펴볼 때도 평가 작업과 메트릭에 따라 텍스트를 어떻게 토큰화할지 고려해야 합니다. 일부 언어(한국어, 태국어, 일본어, 중국어 등)는 항상 공백을 단어 구분자로 사용하지 않기 때문에, 적절하게 분할하려면 언어별 토크나이저가 필요합니다. 그렇지 않으면 [BLEU](https://github.com/EleutherAI/lm-evaluation-harness/issues/212), F1 점수 등과 같은 메트릭에 영향을 미칩니다.

4. **코드 평가 및 문장 끝 토큰**

코드 모델은 일반적으로 `\n\t`를 단일 토큰으로 훈련받았습니다. 이는 텍스트를 생성할 때 종종 `\n\t`를 한 단계에서 생성한다는 것을 의미합니다. `\n`을 문장 끝 토큰(= 생성 중지)으로 정의하는 작업은 `\n\t`가 하나의 토큰으로 예측된 경우 `\n`과 동일하지 않기 때문에 모델이 `\n\t` 이후에도 계속 생성하도록 합니다. 하지만 실제로는 모델이 중지되기를 원할 것입니다. 이런 경우에는 문장 끝 토큰을 업데이트하거나, 최신 토큰의 문자 표현을 역추적하여 생성을 중지(및 잘라내기)하는 메커니즘을 정의해야 합니다.

### MCQA 평가를 위한 쉬운 속도 향상

작업에 필요한 토큰이 하나뿐이라면 MCQA 예측 속도를 크게 높일 수 있습니다.

이렇게 하면 `선택지_수`만큼의 예측(`컨텍스트 + 선택지 1`, `컨텍스트 + 선택지 2` 등)을 실행하는 대신, 단순히 `컨텍스트`에 대한 추론을 실행하고 전체 어휘에 대한 확률 분포(모든 단일 토큰 선택지 포함)를 계산하여 관심 있는 로그확률을 얻을 수 있으며, 이 단계를 한 번에 수행할 수 있습니다.

(이것이 `lighteval`에서 사용하는 방법입니다).

## 생성 평가에서 예상치 못하게 나쁜 결과

항상 먼저 해야 할 일은 모델 생성을 자세히 검사하는 것입니다. 문제 해결 시 자주 찾아봐야 할 사항은 다음과 같습니다:

- 너무 엄격한 모델 출력 구문 분석(메트릭 계산 전)으로 인해 답변이 손실됨
  - 해결: 구문 분석 방식 조정
- 모델이 few shot에서 출력 형식을 따르지 못함(llama 3.2나 Qwen 2.5와 같은 최근 지시 데이터로 훈련된 모델에서 자주 발생)
  - 해결: 프롬프트 형식을 조정하거나, 모델이 few shot에서 형식을 따를 수 있다고 가정
- 정답에 도달하지 못하는 지나치게 장황한 모델(긴 컨텍스트 모델에서 더 자주 발생하며 Qwen 및 CommandR 모델에서 관찰됨)
  - 해결: 허용된 컨텍스트 길이를 늘리거나, 작업 프롬프트에 간결하라는 지시를 추가하거나, 모델이 간결하게 답변할 수 있다고 가정
