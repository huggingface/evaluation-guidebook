# 기본 개념

## 평가 모델(judge model)이란 무엇인가요?
평가 모델은 간단히 말해 **다른 신경망의 출력을 평가하는 데 사용되는 신경망**입니다. 대부분의 경우 텍스트 생성을 평가합니다.

평가 모델의 범위는 작은 특화된 분류기(예를 들어 유해성을 위한 "스팸 필터" 같은 것)부터 대규모 범용 모델이나 소규모 특화된 LLM까지 다양합니다. 후자의 경우, LLM을 평가자로 사용할 때는 모델을 평가하는 방법을 설명하는 프롬프트를 제공합니다(예: `유창성을 0에서 5까지 점수로 매겨주세요. 0은 완전히 이해할 수 없는 경우이고, ...`).

평가 모델을 사용하면 복잡하고 미묘한 특성에 대해 텍스트 점수를 매길 수 있습니다.
예를 들어, 예측과 참조 사이의 정확한 일치는 모델이 올바른 사실이나 숫자를 예측했는지 테스트할 수 있지만, 더 개방적인 경험적 능력(유창성, 시의 품질 또는 입력에 대한 충실도 등)을 평가하려면 더 복잡한 평가자가 필요합니다.

이것이 바로 평가 모델이 등장하는 지점입니다.

평가 모델은 주로 3가지 주요 작업에 사용됩니다:
- *모델 생성물 점수 매기기*: 제공된 척도로 텍스트의 특성(유창성, 유해성, 일관성, 설득력 등)을 평가합니다.
- *쌍별 점수 매기기*: 한 쌍의 모델 출력을 비교하여 주어진 특성에 관해 더 나은 텍스트를 선택합니다.
- *유사성 계산*: 모델 출력과 참조 사이의 유사성을 계산합니다.

*참고: 이 문서에서는 현재 LLM + 프롬프트 접근 방식에 초점을 맞출 것이지만, 분류기 평가 모델이 어떻게 작동하는지 확인해 보는 것도 좋습니다. 이는 다수의 사용 사례에 상당히 견고하고 적합할 수 있으며, 최근 도입된 유망한 보상 모델을 평가자로 사용하는 접근 방식([이 기술 보고서](https://research.nvidia.com/publication/2024-06_nemotron-4-340b)에서 소개되었고, [여기](https://github.com/huggingface/evaluation-guidebook/blob/main/contents/model-as-a-judge/what-about-reward-models.md)에 작은 페이지가 있음)도 살펴볼 만합니다.*

## 평가 LLM의 장단점
평가 LLM은 다음과 같은 이유로 사용되어 왔습니다:
- 인간과 비교했을 때의 **객관성**: 객관적이고 재현 가능한 방식으로 경험적 판단을 자동화합니다.
- **규모와 재현성**: 인간 평가자보다 더 확장성이 높아 대량의 데이터에 대한 점수 매기기를 재현할 수 있습니다.
- **비용**: 새 모델을 훈련할 필요 없이 좋은 프롬프트와 기존의 고품질 LLM에 의존할 수 있어 구현 비용이 저렴합니다. 또한 실제 인간 평가자에게 지불하는 것보다 저렴합니다.
- **인간 판단과의 일치**: 어느 정도 인간의 판단과 상관관계가 있습니다.

그러나 이에 대한 단점도 있습니다:
- LLM 평가자는 객관적으로 보이지만, 인간에게서보다 더 감지하기 어려운 많은 **숨겨진 편향**이 있습니다. 우리가 이러한 편향을 적극적으로 찾지 않기 때문입니다([model-as-a-judge/Tips and tricks] 참조). 또한, 특정하고 통계적으로 견고한 방식으로 설문 질문을 설계하여 인간 편향을 줄이는 방법이 있습니다(이는 약 한 세기 동안 사회학에서 연구되어 왔습니다). 반면 LLM 프롬프팅은 아직 그만큼 견고하지 않습니다. LLM을 사용하여 LLM을 평가하는 것은 미묘하게 편향을 강화하는 반향실(에코 챔버) 효과를 만드는 것에 비유되었습니다.
- 확실히 확장 가능하지만, 품질을 보장하기 위해 검토가 필요한 대량의 데이터를 생성하는 데 기여합니다(예를 들어, LLM 평가자가 사고 과정이나 데이터에 대한 추론을 생성하도록 요청하여 품질을 개선할 수 있지만, 이는 분석할 새로운 인공 데이터를 더 많이 만들어냅니다).
- 구현하기에 저렴하지만, 실제 전문가 인간 평가자에게 비용을 지불하면 특정 사용 사례에 대해 질적으로 더 나은 결과를 얻을 가능성이 높습니다.

## 어떻게 시작할까요?
- 시도해 보고 싶다면, 먼저 Aymeric Roucher가 작성한 첫 번째 LLM을 평가자로 설정하는 방법에 관한 [매우 좋은 가이드](https://huggingface.co/learn/cookbook/en/llm_judge)(⭐)를 읽어보는 것을 권장합니다!
또한 LLM을 사용하여 합성 데이터를 생성하고 업데이트할 수 있는 [distilabel](https://distilabel.argilla.io/latest/) 라이브러리를 시도해 볼 수 있습니다. [Ultrafeedback 논문](https://arxiv.org/abs/2310.01377)의 방법론을 적용한 좋은 [튜토리얼](https://distilabel.argilla.io/latest/sections/pipeline_samples/papers/ultrafeedback/)과 Arena Hard 벤치마크를 구현하는 [벤치마킹 튜토리얼](https://distilabel.argilla.io/latest/sections/pipeline_samples/examples/benchmarking_with_distilabel/)도 있습니다.