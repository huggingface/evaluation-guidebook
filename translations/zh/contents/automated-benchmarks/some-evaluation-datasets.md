# 一些评估测试集

如果你感兴趣的任务已经得到充分研究，很可能评估数据集已经存在了。

下面列出了一些近年来开发构建的评估数据集。需要注意的是：
- 大部分数据集有些 “过时”，因为它们是在 LLM 出现之前构建的，当时是为了评估语言文本的某个特定属性 (如翻译、摘要)，但是可能已经不适合现在的 LLM 评估方法了 (现在的评估方法倾向于通用、整体性)。
	 (*如果你有空余时间可以对下列数据集添加出版日期，会对本文非常有帮助!*)
	 (*这部分后续也会更新包含大语言模型的评估*)
- 有些数据集可能受到污染，因为它们已经在网络上公开了很多年了。不过这并不意味着在你的任务中它们就毫无用处！

## Pre-LLM 数据集

| 评估名称                                       | 任务类型                                                                  | 任务数据                                                                                                                                                                                                                                                      | 任务内容                                                                                                                                            | 源                                                                                          | 数据集                                                                                                                                                                                                                                                                                                                                     | 备注                                                                                                                                                                                                                                                      |
| ---------------------------------------------- | ------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------| ----------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| DeepFix                                        | 编码任务、代码转换、代码修正                                              | 7K 由学生编写的带有错误的 C 程序                                                                                                                                                                                                                              | 修正 C 程序                                                                                                                                         | [论文](https://ojs.aaai.org/index.php/AAAI/article/view/10742)                              |                                                                                                                                                                                                                                                                                                                                            |                                                                                                                                                                                                                                                           |
| MLSum                                          | 生成、多语言、摘要总结                                                    | 1.5 百万篇新闻摘要与文章配对，取材自 Daily Mail、Le Monde、Süddeutsche Zeitung、El Pais、Moskovskij Komsomolets 和 Internet Haber (涵盖英语、法语、德语、西班牙语、俄语和土耳其语)。                                                                          | 总结文章                                                                                                                                            | [论文](https://arxiv.org/abs/2004.14900)                                                    | [Hugging Face](https://huggingface.co/datasets/mlsum)                                                                                                                                                                                                                                                                                      | Palm：以提示符为前缀，将文章截断至 2048 个标记                                                                                                                                                                                                            |
| TransCoder                                     | 编码任务、代码转换                                                        | 用 Python/Java/C++ 语言编写的 852 个并行函数                                                                                                                                                                                                                  | 将一种语言翻译成另一种语言                                                                                                                          | [论文](https://arxiv.org/abs/2006.03511)                                                    | [来自论文](https://github.com/facebookresearch/CodeGen/blob/main/docs/transcoder.md)                                                                                                                                                                                                                                                       |                                                                                                                                                                                                                                                           |
| WMT                                            | 多语言、翻译                                                              | 来自 WMT 机器翻译会议的数据集 - 可用的数据集取决于年份                                                                                                                                                                                                        | 将一种语言翻译成另一种语言                                                                                                                          | [会议](https://www.statmt.org/wmt20/) <br>Replace the 2 digits by the conference year       |                                                                                                                                                                                                                                                                                                                                            |                                                                                                                                                                                                                                                           |
| Adversarial NLI                                | 语言推理                                                                  | 10K 蕴涵数据集是通过人机协作的对抗性攻击生成的，旨在寻找迫使模型预测错误蕴涵标签的谓词 (该数据集使用了来自 StoryCloze、CommonCrawl、Wikipedia、开放注解国家语料库、WikiHow 和 GLUE 的上下文)。                                                                | 预测蕴含关系                                                                                                                                        | [论文](https://arxiv.org/abs/1910.14599)                                                    | [数据](https://dl.fbaipublicfiles.com/anli/anli_v1.0.zip  )<br>[Github](https://github.com/facebookresearch/anli)                                                                                                                                                                                                                          | R1 至 R3 = 数据生成的轮次                                                                                                                                                                                                                                 |
| APPS                                           | 文生代码                                                                  | 10K 用自然语言描述的 Python 编程问题，这些问题是从 LeetCode 网站抓取而来，并附带有一套测试用例。                                                                                                                                                              | 解决 Python 问题                                                                                                                                    | [论文](https://arxiv.org/abs/2105.09938)                                                    | [Github](https://github.com/hendrycks/apps) <br>[数据](https://people.eecs.berkeley.edu/~hendrycks/APPS.tar.gz)                                                                                                                                                                                                                            |                                                                                                                                                                                                                                                           |
| AQuA                                           | 算术、论证                                                                | 100K 选择题 (来源包括 GMAT、GRE 及其他资源)，包含题目/选项/答案解析。                                                                                                                                                                                         | 选择正确的多项选择题答案 (MCQA)                                                                                                                     | [论文](https://arxiv.org/abs/1705.04146)                                                    | [Github](https://github.com/deepmind/AQuA)                                                                                                                                                                                                                                                                                                 | 最佳结果是在添加了外部计算器后获得的                                                                                                                                                                                                                      |
| ARC                                            | 常识、论证                                                                | 8K 小学科学问题：e = 简单题集，c = 挑战题集                                                                                                                                                                                                                   | 选择正确的多项选择题答案 (MCQA)                                                                                                                     | [论文](https://arxiv.org/abs/1803.05457)                                                    | [数据](https://allenai.org/data/arc)                                                                                                                                                                                                                                                                                                       | 注意，这是 AI2 论证 Challenge ，不是抽象与论证语料库。                                                                                                                                                                                                    |
| ASDiv                                          | 分析推理、算术、论证                                                      | 2.3K 数学世界小学问题，收集自各个网站，由一位硕士研究生标注答案和难度级别 (可能是高质量的)                                                                                                                                                                    | 解决问题                                                                                                                                            | [论文](https://aclanthology.org/2020.acl-main.92/)                                          | [Github](https://github.com/chaochun/nlu-asdiv-dataset)                                                                                                                                                                                                                                                                                    |                                                                                                                                                                                                                                                           |
| bAbI                                           | 论证                                                                      | 20 项任务，每项包含 2K 自动生成的问题 + 短场景 (通过模拟的文字冒险游戏生成的连续动作)。                                                                                                                                                                       | 对句子进行推理以选择正确的结论                                                                                                                      | [论文](https://arxiv.org/abs/1502.05698)                                                    | [Github](https://github.com/facebookarchive/bAbI-tasks) <br>[数据](https://research.facebook.com/downloads/babi/)                                                                                                                                                                                                                          | 参见第 4 部分以了解模拟环境及其约束，这是一个相当有趣的想法。对于其他类型的推理，可能不会太难重现。                                                                                                                                                       |
| BBQ                                            | 偏差检测                                                                  | 58K 示例，每个示例包含两种情境 (模糊情境和明确表现出偏见的情境) 、两个问题 (负面问题和非负面问题) 以及可能的答案。这些示例是根据手动模板构建的，并通过众包方式进行检查。                                                                                      | 预测正确且无偏的答案。根据上下文或问题的不同，准确率之间的差异可以构建一个偏见分数。                                                                | [论文](https://aclanthology.org/2022.findings-acl.165/)                                     | [Github](https://github.com/nyu-mll/BBQ/tree/main/data)                                                                                                                                                                                                                                                                                    |                                                                                                                                                                                                                                                           |
| BLiMP                                          | 语言理解                                                                  | 67 个数据集，每个数据集包含人工生成的 1K 最小对，用于测试句法、形态学和语义知识，这些数据集通过 MTurk 平台进行了验证。                                                                                                                                        | 通过检查模型分配给正确句子的对数概率是否更高来衡量准确性。                                                                                          | [论文](https://aclanthology.org/2020.tacl-1.25/)                                            | [Github](https://github.com/alexwarstadt/blimp/tree/master/data)                                                                                                                                                                                                                                                                           | 测试的内容包括：回指一致性、论元结构、绑定、控制/提升、冠词-名词一致性、省略、填充语-空位、不规则形式、孤岛效应、NPI 许可、量化词、主谓一致                                                                                                               |
| BOLD                                           | 生成、有害内容检测                                                        | 从包含种族/宗教/政治/性别/职业群体成员的维基百科句子开头提取的 23K 提示 (例如：女性艺术家，对应性别=女性)。                                                                                                                                                   | 任务: 生成句子结尾，毒性通过一系列指标进行评估 (情感分析、使用分类器等)。在 HELM 中，毒性是通过 Perspective API 进行测量的。                        | [论文](https://arxiv.org/abs/2101.11718)                                                    | [Github](https://github.com/amazon-science/bold/tree/main/prompts)                                                                                                                                                                                                                                                                         |                                                                                                                                                                                                                                                           |
| BooksCorpus                                    | N/A                                                                       | 从网络上抓取的 11K 未出版书籍，每本书超过 20K 单词 (涵盖 16 种不同体裁)。                                                                                                                                                                                     | 在原始论文中，它被用于训练一个句子嵌入模型 — 在模型论文中，它常常被用于污染或困惑度评估。                                                           | [论文](https://arxiv.org/abs/1506.06724)                                                    | [Hugging Face](https://huggingface.co/datasets/bookcorpus)                                                                                                                                                                                                                                                                                 |                                                                                                                                                                                                                                                           |
| BooksCorpus_HELM                               | 生成、记忆                                                                | 来自 BooksCorpus 的 1K 随机抽样书籍。                                                                                                                                                                                                                         | 任务: 从一段文本的随机数量的标记开始，模型必须生成后续内容 — 测量精确和近乎精确的再现。                                                             | [论文](https://arxiv.org/abs/2211.09110)                                                    | [数据](https://drive.google.com/file/d/10uC4jM6tgI1pgtq--07FFHQ2Te7-SXGA/view)                                                                                                                                                                                                                                                             |                                                                                                                                                                                                                                                           |
| BoolQ                                          | 语言推理、语言理解                                                        | 来自 Wikipedia 的 16K 自然发生的是/否问答句子，来源于问题 + 上下文。                                                                                                                                                                                          | 回答多项选择题 (MCQA)                                                                                                                               | [论文](https://arxiv.org/abs/1905.10044)                                                    | [网站](https://super.gluebenchmark.com/tasks)                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                           |
| CB                                             | 语言理解                                                                  | 1.2K 的语篇 (来自《华尔街日报》的新闻、来自 《英国国家语料库》的小说、来自《Switchboard》的对话)，包含上下文 + 目标句子。                                                                                                                                     | 预测承诺蕴含                                                                                                                                        | [论文](https://semanticsarchive.net/Archive/Tg3ZGI2M/Marneffe.pdf)                          | [网站](https://super.gluebenchmark.com/tasks)                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                           |
| Civil comments                                 | 有害内容检测                                                              | 1.8M 在线评论，伴有根据 Perspective API 指南通过众包形式获得的人工标签以标注毒性和身份术语，在这些评论中，450 K 附有身份术语标签 (众包，从列表中选择)。                                                                                                       | 任务: 毒性预测，标签用于识别模型中的偏差区域。                                                                                                      | [论文](https://arxiv.org/abs/1903.04561)                                                    | [Kaggle](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification)<br>[Hugging Face](https://huggingface.co/datasets/civil_comments)                                                                                                                                                                                     | 原始论文包含了一个合成测试集 (77K 示例是从使用50个身份术语的模板生成的，毒性内容的比例为50/50) 和一个人工标注的数据集 (描述在任务内容栏中) —— 我认为可用的数据集是后者。                                                                                  |
| Clean E2E NLG                                  | 描述、生成                                                                | 50K 通过众包生成的餐厅描述，给定关键词和值 (食物类型 = X，预算 = Y……)。                                                                                                                                                                                       |                                                                                                                                                     | [论文](https://arxiv.org/abs/1706.09254)                                                    | [Hugging Face](https://huggingface.co/datasets/e2e_nlg_cleaned)                                                                                                                                                                                                                                                                            | Palm: 在提示符前缀下，将文章截断至2048个标记。                                                                                                                                                                                                            |
| CNN/DailyMail                                  | 完形填空、总结                                                            | 原始数据集：200 K 新文档 (CNN/ Daily Mail 在 2007 年到 2015 年间) 被转换为完形填空格式，通过移除一些文本中的命名实体，并将它们用作关键词。                                                                                                                    | 在 HELM 中: 使用上述文档 (以完整形式) 作为文本进行总结，并使用其重点作为黄金摘要。                                                                  | [论文](https://arxiv.org/abs/1506.03340)                                                    | [Hugging Face](https://huggingface.co/datasets/cnn_dailymail) <br>[数据](https://cs.nyu.edu/~kcho/DMQA/)                                                                                                                                                                                                                                   | (我怀疑这并不能产生非常好的摘要)                                                                                                                                                                                                                          |
| CommonsenseQA                                  | 常识、论证                                                                | 12K 众包的问答对 (基于 ConceptNet 关联初始化)，然后通过质量进行过滤，并从 Google 搜索查询中添加了上下文 > 部分文本可能与 CC 数据重叠                                                                                                                          | 回答多项选择题 (MCQA)                                                                                                                               | [论文](https://aclanthology.org/N19-1421/)                                                  |                                                                                                                                                                                                                                                                                                                                            | 最佳结果是在添加了外部计算器的情况下获得的                                                                                                                                                                                                                |
| Contrast Sets                                  | 生成、健壮性                                                              | 10 组对比集，每组最多 1 K 示例，用于他们的数据集 (详见评论)，这些是由研究人员 (通常是原始论文的作者) 制作的 (增加问题中的推理步骤，用反义词替换词语，改变数量等)。                                                                                            | 遵循原始任务设置并使用新示例，观察性能是否下降 。<br>在 HELM 中: 使用 IMDb 和 DROP 对比集。                                                         | [论文](https://aclanthology.org/2020.findings-emnlp.117/)                                   | [数据](https://allenai.org/data/contrast-sets)                                                                                                                                                                                                                                                                                             | NLVR2、IMDb 情感分析、MATRES 时间关系识别、英文 UD 解析、PERSPECTRUM、DROP、Quoref、ROPES、BoolQ、MC-TACO 。                                                                                                                                              |
| COPA                                           | 常识、语言理解                                                            | 1K 前提 + 因果问题 (附带选项，常识性问题)                                                                                                                                                                                                                     |                                                                                                                                                     | [论文](https://people.ict.usc.edu/~gordon/publications/AAAI-SPRING11A.PDF)                  | [网站](https://super.gluebenchmark.com/tasks)                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                           |
| CoQA                                           | 上下文阅读理解                                                            | 127K 对话式问答，基于给定的上下文 (必须同时提供理由)——由标注者撰写                                                                                                                                                                                            |                                                                                                                                                     | [论文](https://arxiv.org/abs/1808.07042)                                                    | v1.0 from [数据](https://stanfordnlp.github.io/coqa/)                                                                                                                                                                                                                                                                                      |                                                                                                                                                                                                                                                           |
| DataImputation                                 | 现实任务、论证、结构化的数据                                              | 8 个来自多个来源的结构化数据集。                                                                                                                                                                                                                              | 任务: 从一组带有空缺的属性中，模型必须填充这些空缺 (例如: 从电话号码推断城市，从规格推断电话品牌)。                                                 | [论文](https://sxsong.github.io/doc/21icde-imputation.pdf)                                  | [Data restaurant](https://www.cs.utexas.edu/users/ml/riddle/data/restaurant.tar.gz)<br>[Data Buy](https://dbs.uni-leipzig.de/file/Abt-Buy.zip)                                                                                                                                                                                             | 参见表 2 获取所有数据源。<br><br>在 HELM 中：使用子集 Buy 和 Restaurant，将输入转换为自然语言，测试准确性。                                                                                                                                               |
| Digits arithmetics (2D+, 2D-, 3D+, 3D-, …)     | 算术                                                                      | 基本的 n 位数算术任务，包括加法、减法、复合运算，每种运算各有 2K 个示例。                                                                                                                                                                                     | 任务：解决数学问题                                                                                                                                  | [论文](https://arxiv.org/abs/2005.14165)                                                    | [Github](https://raw.githubusercontent.com/openai/gpt-3/master/data/)                                                                                                                                                                                                                                                                      | 所有链接均来自 lm-evaluation-harness/lm_eval/datasets/arithmetic                                                                                                                                                                                          |
| DROP                                           | 算术、上下文阅读理解                                                      | 55K 对抗性问题，这些问题需要 1) 从文本中选择相关项目，并且 2) 对这些项目进行计算 (排序/计数/……) 以获得正确答案。                                                                                                                                              | 任务：选择并计数以提供正确的答案                                                                                                                    | [论文](https://aclanthology.org/N19-1246/)                                                  | [数据](https://allenai.org/data/drop)                                                                                                                                                                                                                                                                                                      |                                                                                                                                                                                                                                                           |
| Dyck language_HELM                             | 符号处理                                                                  | 500 个 D_n 单词，长度在 52 到 100 个字符之间 (“单词”由嵌套的括号组成)，其中最后 i 个字符已被移除。                                                                                                                                                            | 任务：预测唯一的闭合括号序列。                                                                                                                      | [论文](https://arxiv.org/abs/2211.09110)                                                    | [Github](https://github.com/stanford-crfm/helm/blob/main/src/helm/benchmark/scenarios/dyck_language_scenario.py) <br>Also has a different version in BigBench                                                                                                                                                                              |                                                                                                                                                                                                                                                           |
| GSM8K                                          | 分析推理、论证                                                            | 8.5K 各类小学数学问题                                                                                                                                                                                                                                         |                                                                                                                                                     | [论文](https://arxiv.org/abs/2110.14168v2)                                                  | [Github](https://github.com/openai/grade-school-math) <br>[Hugging Face](https://huggingface.co/datasets/gsm8k)                                                                                                                                                                                                                            | 最佳结果是在添加了外部计算器的情况下获得的                                                                                                                                                                                                                |
| HellaSwag                                      | 完形填空                                                                  | 60K 对抗性过滤的多项选择题问答                                                                                                                                                                                                                                | 选择正确的下一个句子 (来自字幕或 WikiHow)。                                                                                                         | [论文](https://aclanthology.org/P19-1472/)                                                  | [Github](https://github.com/rowanz/hellaswag/tree/master/data)                                                                                                                                                                                                                                                                             |                                                                                                                                                                                                                                                           |
| HumanEval                                      | 编码任务、文生代码                                                        | 164 手写编程问题，包含函数签名、文档字符串、函数体 + 单元测试                                                                                                                                                                                                 | 目标是完成函数以通过单元测试。                                                                                                                      | [论文](https://arxiv.org/abs/2107.03374)                                                    | [Hugging Face](https://huggingface.co/datasets/openai_humaneval)                                                                                                                                                                                                                                                                           |                                                                                                                                                                                                                                                           |
| IMDB                                           | 情感分析                                                                  | 50K 条来自 IMDB 的评论，其中正面评价 (评分 ≥ 7) 与负面评价 (评分 ≤ 4) 均衡分布 (不含中立评价)。                                                                                                                                                               | 分类正面/负面评论。                                                                                                                                 | [论文](https://aclanthology.org/P11-1015/)                                                  | [网站](https://ai.stanford.edu/~amaas/data/sentiment/)                                                                                                                                                                                                                                                                                  |                                                                                                                                                                                                                                                              |
| LAMBADA                                        | 完形填空                                                                  | 10K 叙事上下文 (来自 BookCorpus)，随后是一个句子，其中最后一个词被遮掩且必须被预测。特别构建以强制使用上下文。                                                                                                                                                | 预测最后一个词。                                                                                                                                    | [论文](https://aclanthology.org/P16-1144/)                                                  | [Zenodo](https://zenodo.org/record/2630551#.YFJVaWT7S_w)                                                                                                                                                                                                                                                                                   |                                                                                                                                                                                                                                                           |
| Language Modeling Evaluation_HELM              | 语言模型                                                                  | 在 HELM 中编译了多个数据集：WikiText-103、ThePile (特别是 arXiv、BooksCorpus2、Enron Emails、PubMed Central、Wikipedia)、TwitterAAE、ICE。                                                                                                                    | 任务：获取完整序列的条件对数概率 (困惑度测量)。                                                                                                     | [论文](https://arxiv.org/abs/2211.09110)                                                    | [The pile website](https://pile.eleuther.ai/ )<br>[BLIMP Github](https://github.com/alexwarstadt/blimp )<br>[Wikitext data ](https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-raw-v1.zip )<br>[Twitter AAE data](http://slanglab.cs.umass.edu/TwitterAAE/ )<br>[ICE data](https://www.ice-corpora.uzh.ch/en/access.htm) |                                                                                                                                                                                                                                                           |
| LegalSupport                                   | 蕴含, 现实任务、论证                                                      | 20K 个法律蕴含情景，构建于州/联邦法律意见之上 (断言用作上下文，并随机选取 2 个支持来源 ("参见 X，规则"))。                                                                                                                                                    | 任务：确定哪条规则最支持该断言。                                                                                                                    | [论文](https://arxiv.org/abs/2211.09110)                                                    | [数据](https://docs.google.com/uc?export=download&id=1PVoyddrCHChMxYrLhsI-zu7Xzs5S8N77)                                                                                                                                                                                                                                                    |                                                                                                                                                                                                                                                           |
| LinuxKernel_HELM                               | 生成、记忆                                                                | 2K 个从 Linux 内核中随机抽取的函数。                                                                                                                                                                                                                          | 任务：从函数起始的随机行数出发，模型必须生成后续内容——衡量精确和近乎精确的再现。                                                                    | [论文](https://arxiv.org/abs/2211.09110)                                                    | [数据](https://drive.google.com/file/d/1Y5piYwil7T6n8toT_-d7NWqVZHh9NVxJ/view)                                                                                                                                                                                                                                                             |                                                                                                                                                                                                                                                           |
| LSAT                                           | 分析推理、上下文阅读理解、逻辑推理                                        | 10K 个来自法学院入学考试 (分析、逻辑推理和阅读理解) 的问题，包含上下文。                                                                                                                                                                                      | 回答多项选择题 (MCQA) correctly                                                                                                                     | [论文](https://arxiv.org/abs/2108.00648)                                                    | [Github](https://github.com/zhongwanjun/AR-LSAT/tree/main/data)                                                                                                                                                                                                                                                                            |                                                                                                                                                                                                                                                           |
| Magellan Benchmark                             | 现实任务、论证、结构化的数据                                              | 23 个来自多个来源的数据集，包含具有属性的实体。脏数据集包含故意制造的错误，例如属性位于错误的列中、拼写错误等。                                                                                                                                               | 任务：给定来自两个不同表的两个实体，确定它们是否相同。                                                                                              | [论文](https://pages.cs.wisc.edu/~anhai/papers1/deepmatcher-sigmod18.pdf)                   | [Github](https://github.com/anhaidgroup/deepmatcher/blob/master/Datasets.md)                                                                                                                                                                                                                                                               | 很可能 Abt-Buy 和 Buy 是相同的数据集。                                                                                                                                                                                                                    |
| MATH (Mathematics Aptitude Test of Heuristics) | 分析推理、逻辑推理、论证、符号处理                                        | 12.5K 来自真实比赛的数学问题，以自然语言和 LaTeX 格式呈现。                                                                                                                                                                                                   |                                                                                                                                                     | [论文](https://arxiv.org/abs/2103.03874)                                                    | [数据](https://people.eecs.berkeley.edu/~hendrycks/MATH.tar)                                                                                                                                                                                                                                                                               | HELM: 使用一个 "use_chain_of_thought" 标志位。                                                                                                                                                                                                            |
| MAWPS                                          | 算术、论证                                                                | 3.3K 数学应用题 (问题 + 答案 + 模板，来源于现有数据集：AddSub、SingleOp、MultiArith、SingleEq、SimulEq-S 和 SimulEq-L)                                                                                                                                        | 解决数学问题                                                                                                                                        | [论文](https://aclanthology.org/N16-1136/)                                                  | [Github](https://github.com/sroy9/mawps)                                                                                                                                                                                                                                                                                                   | 最佳结果是在添加了外部计算器的情况下获得。                                                                                                                                                                                                                |
| MBPP                                           | 编码任务、文生代码                                                        | 1K 入门级 Python 群体众包编程问题 (描述，解决方案，3 个单元测试用例) - (58 % 数学相关，43% 列表处理，19% 字符串处理，9% 整数序列，以及 2% 其他)。                                                                                                             | 解决 Python 编程问题                                                                                                                                | [论文](https://arxiv.org/abs/2108.07732)                                                    | [Github](https://github.com/google-research/google-research/tree/master/mbpp )<br>[Hugging Face](https://huggingface.co/datasets/mbpp)                                                                                                                                                                                                     | 还包含一个编辑版本 (400 项)，具有明确的提示和良好的签名 (之后可以查看以了解提示对代码生成的影响) + 一个 MathQA - Python 数据集 (MathQA 数据集的改编版本)                                                                                                  |
| MMLU                                           | 语言理解                                                                  | 15K 多选题问答 是从各种在线资源手动收集的，涵盖多个主题 (法律、哲学、经济学、心理学、STEM、医学等， - 从高中到专业水平)。                                                                                                                                     | 回答多项选择题 (MCQA)                                                                                                                               | [论文](https://arxiv.org/abs/2009.03300)                                                    | [Hugging Face](https://huggingface.co/datasets/lukaemon/mmlu )<br>[Github](https://github.com/hendrycks/test )                                                                                                                                                                                                                             | 看起来像是一个强大/高质量的基准线                                                                                                                                                                                                                         |
| MRF (Misinfo Reaction Frames)                  | 生成、虚假信息生成能力                                                    | 200 K 条新闻标题中的声明配对 (气候变化、COVID-19、癌症疾病，详细来源见评论) + 标签 (真实/虚假信息)，前者由 MTurk 工人标注了真实性、传播可能性、作者意图。                                                                                                     | 任务：必须预测黄金标签或生成可能的作者意图、读者感知等……                                                                                            | [论文](https://aclanthology.org/2022.acl-long.222/)                                         | [Github](https://github.com/skgabriel/mrf-modeling)                                                                                                                                                                                                                                                                                        | (包含来自 NELA-GT-2018-2020, SciDCC, Climate-FEVER, CoAID, CoronaVirusFacts/DatosCoronaVirusAlliance 数据库, ESOC Covid-19 错误信息数据集, DETERRENT 的数据)                                                                                              |
| MS MARCO                                       | 问答、检索                                                                | 100 万条匿名化的问题，配有自由格式的人工生成答案 (来自相关网页文档摘录)，其中一些问题还添加了改写版本。                                                                                                                                                       | 原始论文包含 3 个任务：1) 尽可能生成正确的答案，2) 同上但答案即使在没有上下文的情况下也应该合理，3) 对 1000 个段落按照与问题的相关性进行排序。      | [论文](https://arxiv.org/abs/1611.09268)                                                    | [Github](https://microsoft.github.io/msmarco/)                                                                                                                                                                                                                                                                                             | 包含对 QA 数据集在文献综述中的扩展描述 。<br>在 HELM 中，仅考察排序任务，并且通过查看在询问“段落是否回答了查询？”时预测的对数似然性来估计相关性。                                                                                                         |
| MS MARCO TREC, aka TREC 2019                   | 检索                                                                      | 源自 MS MARCO 的数据集，编辑用于段落或文档检索任务，执行完整检索或顶级-n 重排序 (文档为 100，段落为 1000)。(参见 MS MARCO)                                                                                                                                    |                                                                                                                                                     | [论文](https://arxiv.org/abs/2003.07820)                                                    | [数据](https://trec.nist.gov/data/deep2019.html) <br>[Github](https://microsoft.github.io/msmarco/TREC-Deep-Learning-2019.html)                                                                                                                                                                                                            |                                                                                                                                                                                                                                                           |
| MultiRC                                        | 语言理解、问答                                                            | 6K 多选题涵盖多种主题                                                                                                                                                                                                                                         |                                                                                                                                                     | [论文](https://aclanthology.org/N18-1023/)                                                  | [数据](https://super.gluebenchmark.com/tasks)                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                           |
| NarrativeQA                                    | 问答、检索                                                                | 47K 自由形式的人工生成问题和答案，关联到 1.5K 书籍 (Gutenberg 项目) 和电影剧本 (抓取)，并与情节概要相匹配。                                                                                                                                                   | 任务：根据摘要或故事，回答或选择正确答案。                                                                                                          | [论文](https://arxiv.org/abs/1712.07040)                                                    | [Github](https://github.com/deepmind/narrativeqa)                                                                                                                                                                                                                                                                                          | 对于长距离上下文测试，我们可以使用这个数据集从完整的故事中进行问答。对于任何对话系统而言，这可能都很有趣。                                                                                                                                                |
| Natural Questions                              | 开放域/闭书任务、问答                                                     | 207K 汇总的 Google 搜索查询 + 标注的 Wikipedia 示例答案                                                                                                                                                                                                       |                                                                                                                                                     | [论文](https://aclanthology.org/Q19-1026/)                                                  | [数据](https://ai.google.com/research/NaturalQuestions/download)                                                                                                                                                                                                                                                                           |                                                                                                                                                                                                                                                           |
| NewsQA                                         | 问答                                                                      | 100K 人工生成的问答对来自 12K 新闻文章 (CNN)。问题是从标题 + 摘要生成的，答案是从问题 + 文章中得出的，然后通过验证机制保留 。 <br>可能与 CNN / Daily Mail 有交集，因为数据提取脚本是相同的。                                                                  |                                                                                                                                                     | [论文](https://aclanthology.org/W17-2623/)                                                  | [Github](https://github.com/Maluuba/newsqa)                                                                                                                                                                                                                                                                                                |                                                                                                                                                                                                                                                           |
| OpenBookQA                                     | 常识、论证                                                                | 6K 句子，需要运用常识知识进行科学推理，以将结论外推到新情况。                                                                                                                                                                                                 |                                                                                                                                                     | [论文](https://arxiv.org/abs/1809.02789)                                                    | [数据](https://allenai.org/data/open-book-qa)                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                           |
| PIQA                                           | 常识、论证                                                                | 20K 物理常识推理情境                                                                                                                                                                                                                                          | 从上下文中选择正确的操作并作答                                                                                                                      | [论文](https://arxiv.org/abs/1911.11641)                                                    | [数据](https://yonatanbisk.com/piqa/data/)                                                                                                                                                                                                                                                                                                 |                                                                                                                                                                                                                                                           |
| PopularBooksCorpus_HELM                        | 生成、记忆                                                                | 来自 BooksCorpus 的 20 本书，这些书出现在畅销书列表中。                                                                                                                                                                                                       | 任务：从构成书籍第一个段落的随机数量的标记开始，模型必须生成后续内容——衡量精确和近乎精确的再现。                                                    | [论文](https://arxiv.org/abs/2211.09110)                                                    | [数据](https://drive.google.com/file/d/1RT29rRKNNXKgZBhXNbqevLwR440g44it/view)                                                                                                                                                                                                                                                             |                                                                                                                                                                                                                                                           |
| QuAC                                           | 上下文阅读理解                                                            | 100K 个信息寻求型 QA (问答) 情境中的问题 (使用 Wikipedia 来生成数据集)                                                                                                                                                                                        |                                                                                                                                                     | [论文](https://aclanthology.org/D18-1241/)                                                  | [数据](https://quac.ai/)                                                                                                                                                                                                                                                                                                                   |                                                                                                                                                                                                                                                           |
| RACE                                           | 上下文阅读理解                                                            | 100K 个来自中国中学生/高中生英语阅读理解考试的问题                                                                                                                                                                                                            |                                                                                                                                                     | [论文](https://aclanthology.org/D17-1082/)                                                  | [数据](https://www.cs.cmu.edu/~glai1/data/race/)                                                                                                                                                                                                                                                                                           |                                                                                                                                                                                                                                                           |
| RAFT                                           | 现实任务、文本分类                                                        | 11 个自然发生的分类任务数据集的汇编，测试项目数量在 150 到 5 K 之间。                                                                                                                                                                                         | 任务：在少量样本中，从 50 个标注示例出发，提供有意义的标签。(领域：医疗、金融、研究、英语语言、法律、物理、人工智能安全、社交网络)                  | [论文](https://arxiv.org/abs/2109.14076)                                                    | [Hugging Face](https://huggingface.co/datasets/ought/raft)                                                                                                                                                                                                                                                                                 | 语料库: (ADE 语料库 v2、Banking77、NeurIPS 2020 影响声明风险、OneStopEnglish、Overrruling、系统评价纳入、TAI 安全研究、服务条款、TweetEval 恶意内容、Twitter 投诉、半导体组织类型)                                                                        |
| RealToxicityPrompts                            | 生成、有害内容检测                                                        | 100K 自然发生的句子 (从 OpenWebText 语料库中选取，基本上等同于 Reddit，并使用 PerspectiveAPI 对毒性进行评分) 被分成两部分，以创建提示和延续。                                                                                                                 | 任务：从句子开头生成续写内容，然后使用 Perspective API 对生成内容的毒性进行评估。                                                                   | [论文](https://arxiv.org/abs/2009.11462)                                                    | [数据](https://allenai.org/data/real-toxicity-prompts)<br>[Github](https://github.com/allenai/real-toxicity-prompts) (the repo lacks a lot of info)                                                                                                                                                                                        |                                                                                                                                                                                                                                                           |
| ReCoRD                                         | 语言理解                                                                  | 120K 段落/完形填空的查询/答案 示例 来自新闻 (CNN、DailyMail)，并经过人工筛选                                                                                                                                                                                  |                                                                                                                                                     | [论文](https://arxiv.org/abs/1810.12885)                                                    | [数据](https://super.gluebenchmark.com/tasks)                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                           |
| RTE                                            | 语言理解                                                                  | 3K 竞赛数据汇编 关于蕴含关系                                                                                                                                                                                                                                  |                                                                                                                                                     | [论文](https://w4ngatang.github.io/static/papers/superglue.pdf)                             | [数据](https://super.gluebenchmark.com/tasks)                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                           |
| SAT analogies                                  | 语言理解                                                                  | 374 个 2005 年之前的 SAT 类比问题 (a 与 b 的关系如同 c 与多项选择题的关系；词语不是最常见的)                                                                                                                                                                  |                                                                                                                                                     | [论文](https://arxiv.org/abs/2005.14165)                                                    | [Data dev](https://goo.gl/XWjas1)  <br>[Data test](https://goo.gl/BcTtB4)                                                                                                                                                                                                                                                                  |                                                                                                                                                                                                                                                           |
| SIQA                                           | 问答                                                                      |                                                                                                                                                                                                                                                               |                                                                                                                                                     |                                                                                             |                                                                                                                                                                                                                                                                                                                                            |                                                                                                                                                                                                                                                           |
| SQuADv2                                        | 上下文阅读理解                                                            | 结合了 SQuAD 与 50K 不可回答的问题                                                                                                                                                                                                                            | 根据上下文给出答案，但仅在可能的情况下。                                                                                                            | [论文](https://arxiv.org/abs/1806.03822)                                                    | [Github](https://rajpurkar.github.io/SQuAD-explorer/)                                                                                                                                                                                                                                                                                      |                                                                                                                                                                                                                                                           |
| StoryCloze                                     | 完形填空、常识                                                            | 50K 五句话的常识故事                                                                                                                                                                                                                                          | 选择正确的结尾                                                                                                                                      | [论文](https://aclanthology.org/N16-1098/)                                                  | [Hugging Face](https://huggingface.co/datasets/story_cloze)                                                                                                                                                                                                                                                                                |                                                                                                                                                                                                                                                           |
| StrategyQA                                     | 常识、论证                                                                | 2.8K 需要从隐性知识进行推理的问题                                                                                                                                                                                                                             |                                                                                                                                                     | [论文](https://arxiv.org/abs/2101.02235)                                                    |                                                                                                                                                                                                                                                                                                                                            | 最佳结果需添加外部计算器                                                                                                                                                                                                                                  |
| SVAMP                                          | 算术、论证                                                                | 1K 数学应用题 (采样自 ASDivA，质量高于 MAWPS)，具有不同的表述变化                                                                                                                                                                                             |                                                                                                                                                     | [论文](https://aclanthology.org/2021.naacl-main.168/)                                       | [Github](https://github.com/arkilpatel/SVAMP/blob/main/SVAMP.json)                                                                                                                                                                                                                                                                         | 最佳结果需添加外部计算器                                                                                                                                                                                                                                  |
| Synthetic reasoning (natural)                  | 逻辑推理、论证                                                            | 即时生成的合成数据，包含一组合成规则 (条件语句)、事实 (属性) 以及逻辑上的标准输出。                                                                                                                                                                           |                                                                                                                                                     | [论文](https://arxiv.org/abs/2211.09110)                                                    | Can be generated with [Github](https://github.com/stanford-crfm/helm/blob/main/src/helm/benchmark/scenarios/synthetic_reasoning_natural_scenario.py)                                                                                                                                                                                       | 也被称为 HELM 中的 rule_induct                                                                                                                                                                                                                            |
| Synthetic reasoning (symbolic)_HELM            | 逻辑推理、符号处理                                                        | 使用模式模板即时生成的合成数据。                                                                                                                                                                                                                              | 要么测试模型是否能够识别模式（例如“beach + beach - pear”具有“A + A - B”的模式），要么测试模型是否能够在给定的模式中替换字符串。                     | [论文](https://arxiv.org/abs/2211.09110)                                                    | Can be generated with [Github](https://github.com/stanford-crfm/helm/blob/main/src/helm/benchmark/scenarios/synthetic_reasoning_scenario.py)                                                                                                                                                                                               |                                                                                                                                                                                                                                                           |
| TriviaQA                                       | 开放域/闭书任务、问答                                                     | 95K 杂学问答 (组合型问题，语法变异性)                                                                                                                                                                                                                         |                                                                                                                                                     | [论文](https://aclanthology.org/P17-1147/)                                                  | [数据](https://nlp.cs.washington.edu/triviaqa/)                                                                                                                                                                                                                                                                                            |                                                                                                                                                                                                                                                           |
| TruthfulQA                                     | 问答                                                                      | 817 个关于复杂事实主张的问题 (常见误解、错误等)，涵盖 38 个类别，附带真和假的参考答案 + 支持真实答案的来源 (以及额外增加的 380 个问题)。                                                                                                                      |                                                                                                                                                     | [论文](https://arxiv.org/abs/2109.07958)                                                    | [Github](https://github.com/sylinrl/TruthfulQA)                                                                                                                                                                                                                                                                                            |                                                                                                                                                                                                                                                           |
| TyDiQA-GoldP                                   | 多语言、问答                                                              | 204K 多语言 QA 对 (从提示中不限制地引出问题，然后检索维基百科文章，并在文章中选择特定答案 (如果可能的话)) (语言包括：英语、阿拉伯语、孟加拉语、芬兰语、印度尼西亚语、日语、韩语、俄语、泰卢固语、泰语和斯瓦希里语)。                                          | MCQA                                                                                                                                                | [论文](https://aclanthology.org/2020.tacl-1.30/)                                            | [Github](https://github.com/google-research-datasets/tydiqa)                                                                                                                                                                                                                                                                               | 生成的数据集可以展示有趣的问题、目标不清楚的问题和问题与答案语言水平之间的不匹配。可能比其他数据集更具挑战性。                                                                                                                                            |
| Web Questions                                  | 开放域/闭书任务、问答                                                     | 从 Google Search API 中提取了 100K 个 “Wh?” 类型的问题，然后由 MTurkers 进行标注 - 我怀疑部分答案可能已经过时。                                                                                                                                               | MCQA                                                                                                                                                | [论文](https://aclanthology.org/D13-1160/)                                                  | [网站](https://nlp.stanford.edu/software/sempre/)                                                                                                                                                                                                                                                                                          |                                                                                                                                                                                                                                                           |
| WebNLG                                         | 生成、言语化                                                              | 13K 个三元组 (主题, 属性, 客体) 与句子表述之间的映射关系，这些三元组是从 DBPedia 构建的，而 DBPedia 是源自 Wikipedia 的知识库；句子表述是由众包工人完成的，涉及特定主题 (宇航员、大学、纪念碑、建筑物、漫画角色、食品、机场、运动队、文学作品)。              | 任务：以语法正确的方式表达。                                                                                                                        | [论文](https://aclanthology.org/P17-1017/)                                                  | [Hugging Face](https://huggingface.co/datasets/web_nlg)                                                                                                                                                                                                                                                                                    | 有一项关于流畅性的句子选择，生成的句子相对简单，但没有描述注释者/众包者的来源 > 可能部分数据不是“标准英语”。                                                                                                                                              |
| WiC                                            | 语言理解                                                                  | 7K 数据，判断一个词在两个不同语境中出现时是否具有相同含义的分类。                                                                                                                                                                                             |                                                                                                                                                     | [论文](https://aclanthology.org/N19-1128/)                                                  | [Site](https://super.gluebenchmark.com/tasks)                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                           |
| WikiFact_HELM                                  | 完形填空                                                                  | 12 个领域，每个领域包含 1K 三元组 (主题，关系，对象)，这些三元组采样自 Wikipedia 并经过清理。                                                                                                                                                                 | 任务：预测由关系构成的句子中缺失的项目。                                                                                                            | [论文](https://arxiv.org/abs/2211.09110)                                                    | [Codalab](https://worksheets.codalab.org/rest/bundles/0x8c3b60eb7c6b462e822a150f194d3b35/)<br>[Github](https://github.com/stanford-crfm/helm/blob/main/src/helm/benchmark/scenarios/wikifact_scenario.py)                                                                                                                                  |                                                                                                                                                                                                                                                           |
| WikiLingua                                     | 生成、多语言、总结                                                        | 43K 文章 / 摘要对由 WikiHow 构建，涵盖 18 种语言 (在网站上，文章是以每个步骤一个总结句 + 详细段落的形式书写的：在数据集中，摘要为总结句的连接，而文章则是详细段落的组合)。                                                                                    | 总结                                                                                                                                                | [论文](https://aclanthology.org/2020.findings-emnlp.360/)                                   | [Github](https://github.com/esdurmus/Wikilingua )                                                                                                                                                                                                                                                                                          | Palm: 以提示符为前缀，将文章截断至2048个标记<br>我怀疑数据创建可能导致总结基线的语言非常“机械化”，这可能会突出更流畅的总结 (尽管 ROUGE 对此不应该过于敏感)。                                                                                              |
| Winogender                                     | 偏差检测                                                                  |                                                                                                                                                                                                                                                               |                                                                                                                                                     |                                                                                             |                                                                                                                                                                                                                                                                                                                                            |                                                                                                                                                                                                                                                           |
| Winograd                                       | 论证、温格拉德模式                                                        | 273 至 285 个例子，其中必须消除歧义以确定代词指的是谁或什么，这些句子是特意构造的，在统计上是模糊的，但对人类来说不是。                                                                                                                                       | 代词的消歧                                                                                                                                          | [论文](https://dl.acm.org/doi/10.5555/3031843.3031909)                                      | [网站](https://cs.nyu.edu/~davise/papers/WinogradSchemas/WSCollection.xml)                                                                                                                                                                                                                                                                 | 不确定 GPT3 是否在这个数据集或 SuperGLUE 数据集上进行了评估。                                                                                                                                                                                             |
| WinoGrande                                     | 论证、温格拉德模式                                                        | 43K 句子 对抗性 Winograd                                                                                                                                                                                                                                      |                                                                                                                                                     | [论文](https://arxiv.org/abs/1907.10641)                                                    | [网站](https://winogrande.allenai.org/)                                                                                                                                                                                                                                                                                                    |                                                                                                                                                                                                                                                           |
| WSC                                            | 语言理解、温格拉德模式                                                    | Winograd 模式挑战 (见 Winograd)                                                                                                                                                                                                                               |                                                                                                                                                     | [论文](https://w4ngatang.github.io/static/papers/superglue.pdf)                             | [网站](https://super.gluebenchmark.com/tasks)                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                           |
| XSUM                                           | 总结                                                                      | 226K 篇新闻文章 (BBC，2010 年至 2017 年) 与其单句摘要相匹配 (摘自文章)。任务：概括总结。领域：新闻、政治、体育、天气、商业、科技、科学、健康、家庭、教育、娱乐和艺术。                                                                                        |                                                                                                                                                     | [论文](https://aclanthology.org/D18-1206/)                                                  | [Github](https://github.com/EdinburghNLP/XSum)                                                                                                                                                                                                                                                                                             |                                                                                                                                                                                                                                                           |
| XSum                                           | 生成、总结                                                                | 226K 篇来自 BBC (2010 - 2017 年) 的新闻摘要/文章对，从 WayBack 机器中提取。                                                                                                                                                                                   |                                                                                                                                                     | [论文](https://aclanthology.org/D18-1206/)                                                  | [Hugging Face](https://huggingface.co/datasets/xsum)                                                                                                                                                                                                                                                                                       | 可以手动检查最近的知识是否导致了旧新闻摘要中的差异，这可能会很有趣。                                                                                                                                                                                      |

## 可手动重现的数据集想法

| 评估名称                       | 任务类型                                                   | 任务内容                                                                                                                                                                                                                                                                  | 源                                                                                        | 数据集                                                                                   | 备注                                                                                                                                                                                             |     |
| ------------------------------ | ---------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | --- |
| ✍️ GSM8K-Python                | 编码任务、文生代码                                         | GSM8K 数据集的 Python 版本 (8.5K 小学数学问题)                                                                                                                                                                                                                            | [论文](https://arxiv.org/abs/2204.02311)                                                  | N/A                                                                                      |                                                                                                                                                                                                  |     |
| ✍️ MRF                         | 生成、人工评估、虚假信息生成能力                           | 从MRF 数据集抽取了 250 个标题，并依据论点将其分组为 80 个簇。任务要求：基于每个论点及其对应的 5 个标题，模型需要生成能够支持该论点的合理标题。评估人员将对生成的标题进行评价，判断其是否 1) 支持论点，以及 2) 看起来真实可信。                                            | [论文](https://arxiv.org/abs/2211.09110)                                                  | [数据](https://drive.google.com/uc?export=download&id=1uVJbsgPCHFAvH43I6SVvU3Ayo8dh-y_N) | 参见 [报告](https://cset.georgetown.edu/publication/truth-lies-and-automation/) 第 6 页获取关于原始过程的更多说明，以及 HEMLM 论文的章节 8.5.2、E.5 和 5.5。                                     |     |
| ✍️ News article generation     | 生成                                                       | 根据标题和副标题生成了 25 篇文章，80 名人类评估者需要判断这些文章是生成的还是原始的。                                                                                                                                                                                     | [论文](https://arxiv.org/abs/2005.14165)                                                  |                                                                                          |                                                                                                                                                                                                  |     |
| ✍️ Numeracy Prediction         | 符号处理                                                   | 要求模型根据给定的几个例子执行符号回归，并将数字关系应用于新的输入。                                                                                                                                                                                                      |                                                                                           | [论文](https://arxiv.org/abs/2211.09110)                                                 | [Github](https://github.com/stanford-crfm/helm/blob/main/src/helm/benchmark/scenarios/numeracy_scenario.py)                                                                                      |     |
| ✍️ SVG datasets                |                                                            | 可构造一个 SVG 数据集，用于检查模型是否确实能够生成或者分解 SVG 图形                                                                                                                                                                                                      | [Twitter 会话](https://twitter.com/zswitten/status/1631178997508997120)                   |                                                                                          |                                                                                                                                                                                                  |     |
| ✍️ Theory of the mind datasets |                                                            | 可能很容易生成                                                                                                                                                                                                                                                            | [论文](https://arxiv.org/abs/2302.08399)                                                  |                                                                                          |                                                                                                                                                                                                  |     |
| ✍️ Wedging prompts             | 生成, 人工评估、虚假信息生成能力                           | 具有特定意图的 11 个提示 (例如：影响投票行为，通过生成支持/反对 X 的言论来针对特定群体)，并附有 3 个示例。任务：生成后续示例。                                                                                                                                            | [论文](https://cset.georgetown.edu/wp-content/uploads/CSET-Truth-Lies-and-Automation.pdf) | [数据](https://drive.google.com/uc?export=download&id=1kWB3_F4Tobc_oVGC_T-a5DHEh-AB4GTc) | 在 HELM 中：使用人工评估来确定生成的消息 1) 是否针对特定群体；2) 是否支持预期的信息；3) 是否具有分裂性。                                                                                         |     |
| ✍️ Word scrambling             | 符号处理                                                   | 10,000 个示例，涵盖 5 项字符操作任务 (字母循环移位的单词、字母重组、随机插入、反转)。模型需要恢复原始单词。                                                                                                                                                               | [论文](https://arxiv.org/abs/2005.14165)                                                  |                                                                                          | 易于生成/自动化，参见 GPT3 论文的第 3.9.2 节。                                                                                                                                                   |     |
